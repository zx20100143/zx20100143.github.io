---
title: kafka客户端示例代码
date: 2022-02-03 22:34:32
permalink: /pages/4975ea/
categories:
  - 框架
  - Kafka
tags:
  - 
---
http://kafka.apache.org/documentation.html#producerapi

### 发送端

http://kafka.apache.org/23/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html
```java
package com.ceair.screen.flight.service.impl;

import org.apache.kafka.clients.producer.*;

import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;


/**
 * 代码API发送消息
 */
public class KafkaMessageProducer {

    public static void main(String[] args) throws InterruptedException, ExecutionException {

        Properties props = new Properties();
        //props.put("bootstrap.servers", "192.168.229.130:9092,192.168.229.130:9093,192.168.229.130:9094");
        props.put("bootstrap.servers", "192.168.229.130:9092");
        //props.put("acks", "all");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        Producer<String, String> producer = new KafkaProducer<>(props);
        for (int i = 0; i < 5; i++) {
            // 同步方式发送消息
            ProducerRecord<String, String> producerRecord = new ProducerRecord<String, String>("code-test-topic", 0, Integer.toString(i), Integer.toString(i));

            // 同步发送消息
            sendSync(producerRecord, producer);
            // 异步发送消息
            //sendAsync(producerRecord, producer);
        }
        producer.close();
    }

    /**
     * 同步发送消息
     *
     * @param producerRecord
     */
    private static void sendSync(ProducerRecord<String, String> producerRecord, Producer<String, String> producer) throws ExecutionException, InterruptedException {

        Future<RecordMetadata> result = producer.send(producerRecord);
        // 等待消息发送成功的同步阻塞方法
        RecordMetadata metadata = result.get();
        System.out.println("同步方式发送消息结果：" + "topic-" + metadata.topic() + "|partition-"
                + metadata.partition() + "|offset-" + metadata.offset());
    }

    /**
     * 异步发送消息
     *
     * @param producerRecord
     */
    private static void sendAsync(ProducerRecord<String, String> producerRecord, Producer<String, String> producer) {

        // 异步方式发送消息
        producer.send(producerRecord, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.err.println("发送消息失败：" + exception.getStackTrace());
                }
                if (metadata != null) {
                    System.out.println("异步方式发送消息结果：" + "topic-" + metadata.topic() + "|partition-"
                            + metadata.partition() + "|offset-" + metadata.offset());
                }
            }
        });
    }
}



```

### 消费端

http://kafka.apache.org/23/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html

```java
package com.ceair.screen.flight.service.impl;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.Arrays;
import java.util.Properties;

public class KafkaMessageConsumer {

    public static void main(String[] args) {

        Properties props = new Properties();
        props.put("bootstrap.servers", "192.168.229.130:9092,192.168.229.130:9093,192.168.229.130:9094");
        // 消费分组名
        props.put("group.id", "testGroup");

        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        // 默认自动提交offset
        //props.put("enable.auto.commit", "false");
        // 是否自动提交offset
        //props.put("enable.auto.commit", "true");
        // 自动提交offset的间隔时间
        //props.put("auto.commit.interval.ms", "1000");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        // 消费主题
        consumer.subscribe(Arrays.asList("code-test-topic"));
        // 消费指定分区
        //consumer.assign(Arrays.asList(new TopicPartition("topic-replica-zhuge2", 0)));
        while (true) {
			/*
			 * poll() API 是拉取消息的长轮询，主要是判断consumer是否还活着，只要我们持续调用poll()，消费者就会存活在自己所在的group中，
			 * 并且持续的消费指定partition的消息。底层是这么做的：消费者向server持续发送心跳，如果一个时间段（session.
			 * timeout.ms）consumer挂掉或是不能发送心跳，这个消费者会被认为是挂掉了，
			 * 这个Partition也会被重新分配给其他consumer
			 */
            ConsumerRecords<String, String> records = consumer.poll(1000);
            for (ConsumerRecord<String, String> record : records) {
                System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
            }
            if (records.count() > 0) {
                // 提交offset
                consumer.commitSync();
            }

        }
    }
}

```